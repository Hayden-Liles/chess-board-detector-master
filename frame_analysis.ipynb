{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fen_chess_data.utils import distance, find_max_contour_area, find_outer_corners, do_perspective_transform, split_chessboard, preds_to_fen, generate_img\n",
    "\n",
    "axes = [0,0,1,1,]\n",
    "\n",
    "frame_orig = cv2.imread(f'fen_chess_data/data/test_img.jpg')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(frame_orig)\n",
    "\n",
    "plt.title('original frame')\n",
    "plt.show()\n",
    "\n",
    "d = 128\n",
    "frame = cv2.resize(frame_orig, (d, d), interpolation = cv2.INTER_AREA)\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "frame = cv2.Canny(frame, width, height)\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "pts = open('fen_chess_data/data/test_img_yolo_box.txt', 'r').read().split()\n",
    "\n",
    "pts = [int(i) for i in pts]\n",
    "x_orig, y_orig, w_orig, h_orig = tuple(pts)\n",
    "\n",
    "pts = [int( float(i) * (frame.shape[0] / frame_orig.shape[0]) ) for i in pts]\n",
    "x, y, w, h = tuple(pts)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(frame)\n",
    "\n",
    "plt.title('frame downscaled + Canny edge detection')\n",
    "plt.show()\n",
    "\n",
    "cv2.rectangle(frame, (x, y), (x + w, y + h), 255, 1)\n",
    "cv2.rectangle(frame, (x, y), (x + w, y + 10), 255, -1)\n",
    "cv2.putText(frame, 'board', (x, y + 10), cv2.FONT_HERSHEY_PLAIN, 1, (255,255,255), 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(frame)\n",
    "\n",
    "plt.title('YOLO bounding box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = frame_orig[ y_orig : y_orig + h_orig, x_orig : x_orig + w_orig ].copy()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(img)\n",
    "\n",
    "plt.title('YOLO output image, original scale')\n",
    "plt.show()\n",
    "\n",
    "w = img.shape[0]\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 9, 3)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(img, cmap='gray')\n",
    "\n",
    "plt.title('applied adaptiveThreshold')\n",
    "plt.show()\n",
    "\n",
    "contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "ctrs1 = img.copy()\n",
    "ctrs1 = cv2.drawContours(ctrs1, contours, -1, (0, 255, 0), 2).copy()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow( ctrs1 )\n",
    "\n",
    "plt.title('applied findContours')\n",
    "plt.show()\n",
    "\n",
    "contours = find_max_contour_area(contours)\n",
    " \n",
    "img = cv2.drawContours(img, contours, -1, (0, 255, 0), 2).copy()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow( img )\n",
    "\n",
    "plt.title('found contour with largest area')\n",
    "plt.show()\n",
    "\n",
    "c = contours[0]\n",
    "peri = cv2.arcLength(c, True)\n",
    "approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "pts = find_outer_corners(img, approx)\n",
    "\n",
    "for p in pts:\n",
    "    cv2.circle(img, (p[0], p[1]), 3, (255, 0, 0), -1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(img)\n",
    "\n",
    "plt.title('corners of contour with largest area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = frame_orig[ y_orig : y_orig + h_orig, x_orig : x_orig + w_orig ].copy()\n",
    "\n",
    "for p in pts:\n",
    "    cv2.circle(img_orig, (p[0], p[1]), 3, (255, 0, 0), -1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(img_orig)\n",
    "\n",
    "plt.title('corners applied to original YOLO image')\n",
    "plt.show()\n",
    "\n",
    "img_orig = do_perspective_transform(img_orig, pts)\n",
    "img_orig = cv2.resize(img_orig, (256, 256), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "w, h, _ = img_orig.shape\n",
    "dims = list(range(0, w + 1, w // 8))\n",
    "\n",
    "for i in dims:\n",
    "    img_orig = cv2.line(img_orig, (i, 0), (i, w), (0,0,255), 1)\n",
    "    img_orig = cv2.line(img_orig, (0, i), (w, i), (0,0,255), 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(img_orig)\n",
    "\n",
    "plt.title('perspective shift applied')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = frame_orig[ y_orig : y_orig + h_orig, x_orig : x_orig + w_orig ].copy()\n",
    "img_orig = do_perspective_transform(img_orig, pts)\n",
    "img_orig_predict = img_orig.copy()\n",
    "\n",
    "model = tf.keras.models.load_model('fen_chess_data/models/model_best.h5')\n",
    "\n",
    "# predict class of each 64 squares\n",
    "img_orig = cv2.resize(img_orig_predict, (256, 256), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(img_orig)\n",
    "\n",
    "plt.title('original YOLO image w/ perspective shift')\n",
    "plt.show()\n",
    "\n",
    "# convert to B&W but with shape (w, h , 3) for model compatibility\n",
    "img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2GRAY)\n",
    "img_orig = cv2.cvtColor(img_orig, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "imgs = split_chessboard(img_orig)\n",
    "preds = model.predict( np.float32(np.array(imgs)) )\n",
    "\n",
    "i = 60\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(imgs[i])\n",
    "\n",
    "plt.title('E1 square')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.bar(\n",
    "    list('0PRNBQKprnbqk'),\n",
    "    preds[i]\n",
    ")\n",
    "\n",
    "plt.grid()\n",
    "plt.title('E1 square - prediction probabilities')\n",
    "plt.ylabel('prediction probability')\n",
    "plt.show()\n",
    "\n",
    "fen = preds_to_fen(preds)\n",
    "\n",
    "final_img = generate_img(fen, large_dim=400)\n",
    "\n",
    "# visualize final board\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes(axes)\n",
    "\n",
    "ax.imshow(final_img)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('fen: ', fen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
